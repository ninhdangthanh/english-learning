
So, where the standard library (`std`) thread really shines is in what I call an *attached thread*. This is a thread that runs almost independently. Examples of this include timers that need to fire on a periodic cadence, network I/O threads to communicate with other processes, or even interactions with hardware interrupts. The actor model is pretty much built around this concept.

Not long after Rust 1.0 was released, many of us expressed difficulties accessing local scope variables, leading to the addition of scoped threads in the standard library. We’re going to explore how to use these, as they simplify accessing local data by ensuring the lifetime is guaranteed. It is absolutely guaranteed that any threads created within a scope will terminate at the end of that scope. Joining is automatic unless you want to return data, in which case you still need to read the join handles. This setup is perfect for scenarios where you have a large batch of data, want to spawn multiple threads to process it intensively, and then consolidate the results in one place. This pattern is quite common, particularly in the scientific or numerical domains.

The downside, however, is that this approach is more verbose. I've made mistakes myself, forgetting to use the scopes that I create. Threaded scopes originate in the Rust library, which we’ll discuss shortly. With a threaded scope, you’ll notice it’s essentially the same program. We have our atomic counter just like before, but instead of using `std::thread`, we call `thread::scope`. It expects a closure with one parameter: the scope. When you spawn a thread, instead of using `thread::spawn`, you use `scope::spawn`, indicating that the thread should be spawned within that scope. This allows us to safely access shared variables because the program’s lifetime is now deterministic. The Rust compiler can be certain that none of these threads will outlive this scope.

All of this code is covered in the ultimate Rust class that I teach. This approach is excellent for breaking up and processing large amounts of data simultaneously without jumping through hoops or making a mess. Rust gives you the tools needed to divide data into chunks easily. There’s even a `chunks` function if you’re working with vectors, allowing you to split the data into pieces and distribute the workload across CPUs with confidence that you won’t encounter segmentation faults at the end of your program due to a thread outliving your main thread.

Lastly, let’s discuss Rayon. Rayon is nearly as old as Rust itself. If any of you are familiar with Intel’s Threaded Building Blocks for C++, it was one of the inspirations for Rayon. It’s a C++ library that makes threading less cumbersome. The advantages of Rayon include its ease of use in most cases and its excellent performance. If you have an algorithm that can be readily parallelized, Rayon often allows you to write parallel code with minimal effort. The downside is that it offers less control over the process, so if you’re working on something timing-sensitive or complex, requiring interaction with many moving parts, Rayon may not be the right choice. However, in most situations, Rayon simplifies parallelization.

By default, Rayon spawns one thread per available CPU core when you call it for the first time. These threads remain idle until there’s work. We’ll talk about the magic behind managing this later. Rayon doesn’t consider tasks as threads but as units of work, so it’s somewhat of a bridge between async and threads. For computational programs where async is the logical approach, Rayon provides a good middle ground. 

Someone asked if we can prefer threads over async in Rust, and I’ll address this in detail later. Personally, I recommend async for high-performance input-output operations, like network-bound programs that spend a lot of time waiting on databases or network responses. On the other hand, I recommend threads when computation speed is the primary concern. You can also mix both approaches.

Rayon is perfect for situations where you have a specific calculation that needs to be faster. However, if you already have a complex threading system, Rayon might not be suitable as it could add another thread pool on top of the existing one. If you want to parallelize tasks with Rayon, it’s straightforward. We have a function here that performs counting similar to before, using a range. Rayon prefers to work with iterators, and many Rust codes operate on iterators like `map`, `reduce`, `fold`, `sum`, and `for_each`. Rayon fits well into this model.

We created a vector from 0 to 8 and mapped the results. By using Rayon’s prelude and replacing `iter` with `par_iter`, Rayon does all the work for you. When it hits `par_iter`, it creates the thread pool if it hasn’t already, divides the input range into tasks, and feeds these tasks into the pool. The thread pool has work-stealing built in, so if one thread takes longer and others are idle, it automatically redistributes jobs.

By simply changing one line (`iter` to `par_iter`), you can make your program multithreaded. This works with most iterator functions, such as folding, mapping, and processing large datasets. Rayon retains Rust’s safety guarantees. To answer Prabu’s question, yes, you can work with mutex variables in Rayon. It works with scoped threads, guaranteeing safe return. For read-only access, you don't even need a mutex. If you wrap it in a mutex, you can manage it as any other shared variable.

Rayon simplifies multithreading, but here’s a caution: someone recently used Rayon’s parallel sort feature, but their program slowed down. The reason was that Rust’s single-threaded sort is exceptionally fast, and dividing a million 64-bit integers across multiple threads was slower than sorting them in a single thread. So, always make sure there’s enough work to justify multithreading; otherwise, it may hinder performance.

In summary, use `std::thread` for building complex architectures where you detach independent tasks. Use scoped threads when you need to divide data and share access without duplicating it. Rayon is ideal when threads aren’t the focus of your program, but you have tasks suitable for CPU distribution. Rayon simplifies parallelization, and while it’s easy to use, no one will complain if your program speeds up significantly with minimal code.

If it fits your project’s needs, try Rayon. It might just solve your problem efficiently.
