
It's amazing how easy it is to take the process of converting source code to machine code for granted. We invoke the compiler, and out pops our binary, which we can run without really thinking about it. However, if we want to improve our skills as developers, it is crucial that we understand the steps that take our code from being human-readable to a format the computer can execute.

The topics we're going to discuss today are each extremely complicated in their own right, but by spending 10 minutes a day on each of these topics, you can, over time, become a 10x developer without even realizing it. In this video, we're going to explore the idea of compilers, executable file formats, and how we get that executable off the disk, loaded into RAM, and executing on our computer.

Before we start, some of you here may be brand new to computer science. Maybe you've written zero lines of code. What if I told you there's a way to learn computer science that is free, easy, doesn't break the bank, and does not cost thousands of dollars? The sponsor of today's video is **Brilliant.org**. Brilliant is the best way to learn data science, math, and computer science interactively. 

My favorite part about Brilliant is that it's not a boring lecture series where you sit for an hour, watch a video, and then take a test afterward. The content is bite-sized, allowing you to learn as you go. If you're not sure where to start with programming, the **New Thinking and Code Course** gets you designing real-world programs that solve real-world problems. After watching this video, you can go to my URL, [www.brilliant.org/thelevellearning](www.brilliant.org/thelevellearning), for a free 30-day trial and 20% off your first annual subscription. Thanks again, Brilliant, for sponsoring this video!

It all starts by picking a programming language. At the end of the day, computers can only understand machine code—the ones and zeros that correspond to specific transistors in the hardware of the CPU, which make the CPU perform tasks. Now, we could open the Intel assembly manual and write the binary by hand ourselves. This is entirely possible, but it's a bit crazy—no one in their right mind would do this, except for maybe this guy.

If we make a simple mistake in our binary and miss a single bit, we could accidentally flip the entire logic of our program—from a "jump if" to a "jump not". To fix this, we have programming languages: code that is more human-readable than machine code, which eventually becomes machine code that our CPU can understand. But there's a problem—if we tried to feed the source code directly into the CPU, it would have no idea what we're talking about. The CPU does not speak our English-like language and cannot run our code. So, we need a tool to convert our human code into machine code. Hence, compilers.

Compilers take our human-like code (C, for example) and convert it into the ones and zeros that the CPU knows how to execute. This is done in a roughly three-stage process: **Lexing**, **Parsing**, and **Code Generation**. In the Lexing stage, the compiler takes our strings and turns them into tokens, each token representing a different part of the expression. During lexical analysis, the compiler also ensures that our code adheres to the language's grammar. For example, `int XX` is not valid C code.

Once all our code is converted into tokens, the compiler moves to the next stage: Parsing. The tokens are parsed into a structure known as an **Abstract Syntax Tree** (AST), representing the functional nature of our program in terms of what it is meant to execute as a series of tokenized expressions. Certain compilers, like LLVM, may convert our code into what is called an **Intermediate Representation** (IR). An IR is a universal assembly language that represents CPU features without adhering to a specific computer architecture. 

After the IR is generated, we move on to code generation, where the compiler outputs the specific CPU target machine code for our processor (e.g., Intel assembly). However, the compiler can't just output a binary blob; it must produce a format that the operating system knows how to interpret, which leads us to our next topic: **Executable File Formats**.

When we run our code, a lot goes on under the hood. For example, we may need to link in external libraries like `libc` or manage uninitialized variables that occupy a particular memory area. All these things must be stored in a way the operating system can handle; otherwise, our code won't work.

To manage this, the compiler must know the format to put our code in so that it can work with the operating system. In this video, we're discussing the **Executable and Linkable Format** (ELF), the file format Linux uses for its executables. The ELF has many features, but the ones we'll cover include the ELF header, ELF segments, and ELF sections. 

The ELF header is straightforward; it specifies that this is an ELF file format and describes some details like the number of segments and sections. The most important parts of the ELF are the segments: the **text segment**, where your code resides, which is readable and executable, and the **data segment**, where predefined data is stored, which is readable and writable but not executable. These segments provide the kernel with specific information about how to load our compiled code into memory. 

This ELF format is used by the kernel to correctly load the program into memory. It's crucial that your segments are formatted properly; otherwise, the kernel won't load your program. Once the compiler has produced this file, we arrive at the final stage of the process, and arguably one of the most complex: executing the program.

Now, the moment we've all been waiting for—we get to run our program! But let's take a step back; it gets complicated quickly. To start, the **parent process** must inform the operating system that it wants to run your program. You might be wondering, "Wait, what is the parent process?" When you run a program, every program needs a parent process—the one that informed the kernel it wants to run your program. 

In Linux, when you run your program on the command line, it runs in a shell (like `sh` or `bash`). The shell acts as the parent of your process, as it tells the kernel to run your program. The parent program in Linux uses a syscall called `execve` to inform the operating system, taking the program path and arguments as parameters. 

This syscall alerts the kernel, "Hey, I want to run this program." Only the kernel, in its privileged environment, can execute this function, a privilege not available to the user. When the kernel gets this signal, it does several important things. First, it looks at your ELF to identify three key locations: the **text segment**, where the code resides; the **data segment**, where initialized data lives; and the **BSS segment**, for uninitialized data. Any variable initialized to zero by default is placed in the BSS. 

The kernel allocates all these segments in memory based on the ELF metadata emitted by the compiler. However, there's another important segment we haven't covered: **PT_INTERP**. Here's the twist—when you run a program in Linux, you actually run two programs. Your program gets loaded by the kernel, but it looks into your ELF for a loader. 

If your program depends on external libraries, the kernel uses a dynamic linker that runs alongside your program. This linker parses your ELF and resolves symbols needing external linkage, like dependencies on `libc`. Once resolved, the dynamic linker transfers control to your program, executing your start symbol. Amazing—we've reached the end! 

What an adventure! The world of programming is vast, filled with deep rabbit holes. By dedicating just 10 minutes a day to learning something new about these topics, you'll become a next-level programmer. Before you go, if you want to learn how NASA writes code that works in space without crashing, check out this video!

