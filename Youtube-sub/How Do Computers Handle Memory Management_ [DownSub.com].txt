
In this video, we're going to talk about how computers handle memory management.

My name is Kevin Way, and I'm here to help you land your dream job in tech. Different systems employ various techniques for memory management, each with its own advantages and disadvantages. Being able to discuss the pros and cons of each may be beneficial in your upcoming technical interviews.

Before we dive in, if you're enjoying these tech interview prep videos, make sure you like, subscribe, and hit the notification bell for new videos every single week. It might seem minor, but doing these things really helps the algorithm find our content.

Memory management deals with how systems allocate and free memory during the execution of a program. Older languages like C or C++ don't have any form of automatic memory management. Developers had to allocate and release memory explicitly by calling `malloc` and `free` in C, and `new` and `delete` in C++. A critical requirement for managing memory is ensuring each allocation is matched with exactly one deallocation. If the developer forgets to release allocated memory, the system can't reclaim it, leading to memory leaks, which means the memory remains unusable until the program terminates. Over time, this results in the program running out of memory and crashing, which can be particularly problematic if it occurs on a critical server or within the operating system.

Similarly, if the developer accidentally attempts to release previously deallocated memory, it might result in releasing memory that is currently in use, leading to unpredictable and often disastrous consequences. Although manual memory management imposes the least overhead on the program, it also leads to the most bugs, as it depends on developers remembering to manually call the correct deallocation functions. This has caused many issues in the past.

As a result, most modern programming languages have automatic memory management mechanisms. The two most common patterns are garbage collection and automatic reference counting. Let’s delve deeper into these two patterns, starting with garbage collection.

Garbage collection is the most prevalent pattern for deallocating memory, used by Java, Go, and many other modern languages. When the system detects that a program is running low on memory, it pauses program execution and runs a garbage collector. The garbage collector marks all the in-use memory in the program, compacts the heap by moving all reachable memory to the beginning of the heap, updates references to the new locations, and finally releases all unreachable memory. It also optimizes the number of times it runs by determining which memory is short-lived and which needs to persist longer. It does so by assigning a generation to each memory block. Memory that persists through multiple garbage collection cycles is promoted from one generation to the next. The garbage collector clears older generations less frequently because it assumes this memory will likely persist throughout the process’s lifetime.

Now, let's cover automatic reference counting, the other common approach for automatic memory management. With automatic reference counting, a reference count is maintained for each piece of allocated memory as the program executes. When a variable references an object, the reference count for that object is incremented. When the variable stops referencing the object, the reference count is decremented. When the reference count of an object reaches zero, the memory is immediately freed. This approach is employed by Apple in both Objective-C and Swift on iOS.

Garbage collection is the most developer-friendly option, as it removes the mental burden of managing references. However, it can result in the program being paused at unpredictable points during execution, making it less suitable for real-time and user-interactive apps. This is one of the main reasons Apple opts for automatic reference counting in iOS. While the developer overhead is higher, as it requires developers to be cautious about inadvertently creating reference cycles that cause memory leaks, it provides better performance for highly interactive apps. This approach also requires extra space to store the reference count for each object, adding a bit of overhead, but it performs better for a variety of interactive applications.

I hope this helps provide an overview of how memory management works. In most situations, the development team may not have a choice in the memory management strategy, as it is determined by the language the project uses. However, developers need to optimize the experience based on the limitations of the language or platform.

For more interview prep content, Exponent offers the best resources to help you ace your interview, including in-depth courses, private coaching, and a community of experts ready to assist with even the toughest questions. Hit that subscribe button for new videos every week, and visit tryexponent.com to become a member today. Thanks for watching!
