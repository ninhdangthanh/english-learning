Event-driven, sometimes called asynchronous, and request-response, also known as synchronous, are two common software architecture patterns used to integrate microservices. Understanding the difference between these two is critical to building scalable and efficient applications.

In this video, we cover the key differences between these two patterns, including the pros and cons of each approach. Imagine that we have an e-commerce application that is responsible for taking customer orders. In a typical microservice-based architecture, we have a variety of services responsible for different roles.

After a customer places an order, an API gets executed in the ORD service. After it saves the record in its database, it needs to notify other downstream services, like a warehouse operation service, a fraud detection service, and an analytics service. The question is, which approach should it use: event-driven or request-response?

In an event-driven architecture, the order service would publish a message whenever a new order gets placed. They would do this by interacting with an entity called a topic. Topics are logical entities used to facilitate asynchronous communication. Topics have an endpoint that message producers invoke to notify message consumers of changes. Producers of messages are also called publishers, and consumers are called subscribers, hence the name pub/sub, a common term to describe event-based architectures.

In our example, the ORD service would publish to an orders topic. The topic system would asynchronously notify subscribers, either by invoking a predefined endpoint or publishing a message to a queue, which they will consume. Topics and queues are components provided by systems that facilitate event-driven applications. Two of the most popular ones are Apache Kafka and AWS's SNS plus SQS services.

One of the pros of this event-driven system is its simplicity. The order service only needs to send a single message to notify multiple downstream subscribers. This means that subscribers can be added or removed without affecting the order service's core logic. This concept is called loose coupling and is one of the major benefits of using event-driven systems. Conversely, one main con is the additional complexity in understanding the relationships between systems and the flow of their events. Secondly, there is a possibility of data inconsistency between publishers and subscribers. This can be due to latency, errors, and many other reasons.

In contrast, the request-response model involves a consumer calling the API of a producer to receive information. The issue with this approach is that the consumer will need to continuously poll the producer to discover any new changes. This can cause unnecessary load on the producer system. An alternative approach, also using request-response, is to introduce additional steps. When a customer places an order, after they've saved the record, they can invoke the APIs of dependent systems to notify them of the change. This approach can be useful when the producing system needs a real-time acknowledgment from the dependent system that it has processed the event.

There are many cons to this approach. The first is the additional latency required to notify dependent systems. The second is the need to modify code whenever new dependencies get added or removed. The third is related to complex partial failure scenarios when invoking the APIs of dependencies. It's possible that some will fail, which will require retries and potential fallback plans to address.

Besides this, event-driven systems are becoming increasingly popular due to their ease of use and flexibility for adding new use cases. However, there are pros and cons to both this new trend and the traditional request-response model. The key is in understanding which one is right for you.